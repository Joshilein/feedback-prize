{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79b3465",
   "metadata": {},
   "source": [
    "# Approach: Embedding + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3f597a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "978a2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../data/train.csv\")\n",
    "test = pd.read_csv(\"../../data/test.csv\")\n",
    "\n",
    "# IN KAGGLE:\n",
    "#train = pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/train.csv\")\n",
    "#test = pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad0751",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "df7af4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 123/123 [00:10<00:00, 12.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# SBERT Modell laden\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# IN KAGGLE (UPLOAD sbert_model.zip TO NOTEBOOK AS DATASET FIRST):\n",
    "#sbert_model = SentenceTransformer(\"/kaggle/input/sentence-bert\")\n",
    "\n",
    "# Erzeuge Embeddings\n",
    "embeddings = sbert_model.encode(train[\"full_text\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Optional: Embeddings in die DataFrame schreiben\n",
    "train[\"embedding\"] = embeddings.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1c412",
   "metadata": {},
   "source": [
    "### Define Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0619559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SBERTEmbeddingDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.embeddings = dataframe[\"embedding\"].tolist()\n",
    "        self.labels = dataframe[[\"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"]].values.astype(float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedding = torch.tensor(self.embeddings[idx], dtype=torch.float)\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return embedding, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9ee9d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SBERTEmbeddingDataset(train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ea417",
   "metadata": {},
   "source": [
    "### Define simple Feed Forward Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "108f7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(384, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.Dropout(0.4),\n",
    "\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(256),\n",
    "        nn.Dropout(0.3),\n",
    "\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.Dropout(0.2),\n",
    "\n",
    "        nn.Linear(128, 6)  # Multi-Target Regression\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f8b585",
   "metadata": {},
   "source": [
    "### Train Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eec753c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCRMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss(reduction='none')  # wichtig!\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        # preds/targets: [batch_size, num_targets]\n",
    "        colwise_mse = self.mse(preds, targets).mean(dim=0)  # Mittelwert pro Spalte\n",
    "        colwise_rmse = torch.sqrt(colwise_mse + 1e-8)       # RMSE pro Ziel\n",
    "        return colwise_rmse.mean()                          # Mittelwert über Ziele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0d0991e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_kfold(dataset, model_fn, k=5, num_epochs=10, lr=1e-3, batch_size=32):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_val_losses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        print(f\"\\n--- Fold {fold + 1} ---\")\n",
    "\n",
    "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size)\n",
    "\n",
    "        model = model_fn().to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "        loss_fn = MCRMSELoss()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for xb, yb in train_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                preds = model(xb)\n",
    "                loss = loss_fn(preds, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader.dataset)\n",
    "            print(f\"Epoch {epoch+1}: Train Loss = {avg_loss:.4f}\")\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    preds = model(xb)\n",
    "                    loss = loss_fn(preds, yb)\n",
    "                    val_loss += loss.item() * xb.size(0)\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "            scheduler.step(avg_val_loss)\n",
    "            print(f\"Fold {fold + 1} Epoch {epoch+1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        fold_val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"\\nAverage Validation Loss across {k} folds: {sum(fold_val_losses)/k:.4f}\")\n",
    "    return fold_val_losses, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4c421b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      "Epoch 1: Train Loss = 2.9261\n",
      "Fold 1 Epoch 1 Validation Loss: 2.4199\n",
      "Epoch 2: Train Loss = 1.4318\n",
      "Fold 1 Epoch 2 Validation Loss: 0.7171\n",
      "Epoch 3: Train Loss = 0.8524\n",
      "Fold 1 Epoch 3 Validation Loss: 0.6066\n",
      "Epoch 4: Train Loss = 0.7816\n",
      "Fold 1 Epoch 4 Validation Loss: 0.5831\n",
      "Epoch 5: Train Loss = 0.7530\n",
      "Fold 1 Epoch 5 Validation Loss: 0.5922\n",
      "Epoch 6: Train Loss = 0.7035\n",
      "Fold 1 Epoch 6 Validation Loss: 0.5769\n",
      "Epoch 7: Train Loss = 0.6840\n",
      "Fold 1 Epoch 7 Validation Loss: 0.5652\n",
      "Epoch 8: Train Loss = 0.6646\n",
      "Fold 1 Epoch 8 Validation Loss: 0.5743\n",
      "Epoch 9: Train Loss = 0.6497\n",
      "Fold 1 Epoch 9 Validation Loss: 0.5685\n",
      "Epoch 10: Train Loss = 0.6430\n",
      "Fold 1 Epoch 10 Validation Loss: 0.5660\n",
      "Epoch 11: Train Loss = 0.6247\n",
      "Fold 1 Epoch 11 Validation Loss: 0.5643\n",
      "Epoch 12: Train Loss = 0.6132\n",
      "Fold 1 Epoch 12 Validation Loss: 0.5564\n",
      "Epoch 13: Train Loss = 0.6161\n",
      "Fold 1 Epoch 13 Validation Loss: 0.5625\n",
      "Epoch 14: Train Loss = 0.6038\n",
      "Fold 1 Epoch 14 Validation Loss: 0.5597\n",
      "Epoch 15: Train Loss = 0.5931\n",
      "Fold 1 Epoch 15 Validation Loss: 0.5661\n",
      "Epoch 16: Train Loss = 0.5878\n",
      "Fold 1 Epoch 16 Validation Loss: 0.5558\n",
      "Epoch 17: Train Loss = 0.5853\n",
      "Fold 1 Epoch 17 Validation Loss: 0.5574\n",
      "Epoch 18: Train Loss = 0.5745\n",
      "Fold 1 Epoch 18 Validation Loss: 0.5579\n",
      "Epoch 19: Train Loss = 0.5691\n",
      "Fold 1 Epoch 19 Validation Loss: 0.5632\n",
      "Epoch 20: Train Loss = 0.5597\n",
      "Fold 1 Epoch 20 Validation Loss: 0.5648\n",
      "Epoch 21: Train Loss = 0.5678\n",
      "Fold 1 Epoch 21 Validation Loss: 0.5612\n",
      "Epoch 22: Train Loss = 0.5554\n",
      "Fold 1 Epoch 22 Validation Loss: 0.5622\n",
      "Epoch 23: Train Loss = 0.5509\n",
      "Fold 1 Epoch 23 Validation Loss: 0.5645\n",
      "Epoch 24: Train Loss = 0.5573\n",
      "Fold 1 Epoch 24 Validation Loss: 0.5592\n",
      "Epoch 25: Train Loss = 0.5491\n",
      "Fold 1 Epoch 25 Validation Loss: 0.5616\n",
      "\n",
      "--- Fold 2 ---\n",
      "Epoch 1: Train Loss = 2.9644\n",
      "Fold 2 Epoch 1 Validation Loss: 2.3038\n",
      "Epoch 2: Train Loss = 1.4650\n",
      "Fold 2 Epoch 2 Validation Loss: 0.6939\n",
      "Epoch 3: Train Loss = 0.8607\n",
      "Fold 2 Epoch 3 Validation Loss: 0.6486\n",
      "Epoch 4: Train Loss = 0.8007\n",
      "Fold 2 Epoch 4 Validation Loss: 0.6096\n",
      "Epoch 5: Train Loss = 0.7437\n",
      "Fold 2 Epoch 5 Validation Loss: 0.5903\n",
      "Epoch 6: Train Loss = 0.7208\n",
      "Fold 2 Epoch 6 Validation Loss: 0.5638\n",
      "Epoch 7: Train Loss = 0.6981\n",
      "Fold 2 Epoch 7 Validation Loss: 0.5730\n",
      "Epoch 8: Train Loss = 0.6711\n",
      "Fold 2 Epoch 8 Validation Loss: 0.5665\n",
      "Epoch 9: Train Loss = 0.6488\n",
      "Fold 2 Epoch 9 Validation Loss: 0.5815\n",
      "Epoch 10: Train Loss = 0.6376\n",
      "Fold 2 Epoch 10 Validation Loss: 0.5614\n",
      "Epoch 11: Train Loss = 0.6379\n",
      "Fold 2 Epoch 11 Validation Loss: 0.5621\n",
      "Epoch 12: Train Loss = 0.6214\n",
      "Fold 2 Epoch 12 Validation Loss: 0.5571\n",
      "Epoch 13: Train Loss = 0.6141\n",
      "Fold 2 Epoch 13 Validation Loss: 0.5590\n",
      "Epoch 14: Train Loss = 0.6048\n",
      "Fold 2 Epoch 14 Validation Loss: 0.5609\n",
      "Epoch 15: Train Loss = 0.6050\n",
      "Fold 2 Epoch 15 Validation Loss: 0.5653\n",
      "Epoch 16: Train Loss = 0.5922\n",
      "Fold 2 Epoch 16 Validation Loss: 0.5511\n",
      "Epoch 17: Train Loss = 0.5888\n",
      "Fold 2 Epoch 17 Validation Loss: 0.5510\n",
      "Epoch 18: Train Loss = 0.5787\n",
      "Fold 2 Epoch 18 Validation Loss: 0.5551\n",
      "Epoch 19: Train Loss = 0.5836\n",
      "Fold 2 Epoch 19 Validation Loss: 0.5531\n",
      "Epoch 20: Train Loss = 0.5661\n",
      "Fold 2 Epoch 20 Validation Loss: 0.5499\n",
      "Epoch 21: Train Loss = 0.5612\n",
      "Fold 2 Epoch 21 Validation Loss: 0.5517\n",
      "Epoch 22: Train Loss = 0.5655\n",
      "Fold 2 Epoch 22 Validation Loss: 0.5572\n",
      "Epoch 23: Train Loss = 0.5762\n",
      "Fold 2 Epoch 23 Validation Loss: 0.5526\n",
      "Epoch 24: Train Loss = 0.5531\n",
      "Fold 2 Epoch 24 Validation Loss: 0.5531\n",
      "Epoch 25: Train Loss = 0.5494\n",
      "Fold 2 Epoch 25 Validation Loss: 0.5544\n",
      "\n",
      "--- Fold 3 ---\n",
      "Epoch 1: Train Loss = 2.9618\n",
      "Fold 3 Epoch 1 Validation Loss: 2.5002\n",
      "Epoch 2: Train Loss = 1.4592\n",
      "Fold 3 Epoch 2 Validation Loss: 0.7791\n",
      "Epoch 3: Train Loss = 0.8717\n",
      "Fold 3 Epoch 3 Validation Loss: 0.6307\n",
      "Epoch 4: Train Loss = 0.7786\n",
      "Fold 3 Epoch 4 Validation Loss: 0.6122\n",
      "Epoch 5: Train Loss = 0.7491\n",
      "Fold 3 Epoch 5 Validation Loss: 0.5801\n",
      "Epoch 6: Train Loss = 0.7266\n",
      "Fold 3 Epoch 6 Validation Loss: 0.5822\n",
      "Epoch 7: Train Loss = 0.6864\n",
      "Fold 3 Epoch 7 Validation Loss: 0.5892\n",
      "Epoch 8: Train Loss = 0.6723\n",
      "Fold 3 Epoch 8 Validation Loss: 0.5666\n",
      "Epoch 9: Train Loss = 0.6569\n",
      "Fold 3 Epoch 9 Validation Loss: 0.5724\n",
      "Epoch 10: Train Loss = 0.6393\n",
      "Fold 3 Epoch 10 Validation Loss: 0.5753\n",
      "Epoch 11: Train Loss = 0.6281\n",
      "Fold 3 Epoch 11 Validation Loss: 0.5715\n",
      "Epoch 12: Train Loss = 0.6084\n",
      "Fold 3 Epoch 12 Validation Loss: 0.5628\n",
      "Epoch 13: Train Loss = 0.6058\n",
      "Fold 3 Epoch 13 Validation Loss: 0.5650\n",
      "Epoch 14: Train Loss = 0.6112\n",
      "Fold 3 Epoch 14 Validation Loss: 0.5613\n",
      "Epoch 15: Train Loss = 0.5941\n",
      "Fold 3 Epoch 15 Validation Loss: 0.5571\n",
      "Epoch 16: Train Loss = 0.5800\n",
      "Fold 3 Epoch 16 Validation Loss: 0.5562\n",
      "Epoch 17: Train Loss = 0.5799\n",
      "Fold 3 Epoch 17 Validation Loss: 0.5581\n",
      "Epoch 18: Train Loss = 0.5848\n",
      "Fold 3 Epoch 18 Validation Loss: 0.5542\n",
      "Epoch 19: Train Loss = 0.5805\n",
      "Fold 3 Epoch 19 Validation Loss: 0.5642\n",
      "Epoch 20: Train Loss = 0.5650\n",
      "Fold 3 Epoch 20 Validation Loss: 0.5626\n",
      "Epoch 21: Train Loss = 0.5535\n",
      "Fold 3 Epoch 21 Validation Loss: 0.5616\n",
      "Epoch 22: Train Loss = 0.5548\n",
      "Fold 3 Epoch 22 Validation Loss: 0.5622\n",
      "Epoch 23: Train Loss = 0.5416\n",
      "Fold 3 Epoch 23 Validation Loss: 0.5633\n",
      "Epoch 24: Train Loss = 0.5507\n",
      "Fold 3 Epoch 24 Validation Loss: 0.5572\n",
      "Epoch 25: Train Loss = 0.5385\n",
      "Fold 3 Epoch 25 Validation Loss: 0.5600\n",
      "\n",
      "--- Fold 4 ---\n",
      "Epoch 1: Train Loss = 2.9768\n",
      "Fold 4 Epoch 1 Validation Loss: 2.4585\n",
      "Epoch 2: Train Loss = 1.4518\n",
      "Fold 4 Epoch 2 Validation Loss: 0.7339\n",
      "Epoch 3: Train Loss = 0.8617\n",
      "Fold 4 Epoch 3 Validation Loss: 0.6258\n",
      "Epoch 4: Train Loss = 0.7731\n",
      "Fold 4 Epoch 4 Validation Loss: 0.6153\n",
      "Epoch 5: Train Loss = 0.7385\n",
      "Fold 4 Epoch 5 Validation Loss: 0.6124\n",
      "Epoch 6: Train Loss = 0.7076\n",
      "Fold 4 Epoch 6 Validation Loss: 0.6127\n",
      "Epoch 7: Train Loss = 0.6780\n",
      "Fold 4 Epoch 7 Validation Loss: 0.5893\n",
      "Epoch 8: Train Loss = 0.6682\n",
      "Fold 4 Epoch 8 Validation Loss: 0.6012\n",
      "Epoch 9: Train Loss = 0.6671\n",
      "Fold 4 Epoch 9 Validation Loss: 0.5839\n",
      "Epoch 10: Train Loss = 0.6410\n",
      "Fold 4 Epoch 10 Validation Loss: 0.5875\n",
      "Epoch 11: Train Loss = 0.6265\n",
      "Fold 4 Epoch 11 Validation Loss: 0.5770\n",
      "Epoch 12: Train Loss = 0.6113\n",
      "Fold 4 Epoch 12 Validation Loss: 0.5865\n",
      "Epoch 13: Train Loss = 0.6140\n",
      "Fold 4 Epoch 13 Validation Loss: 0.5891\n",
      "Epoch 14: Train Loss = 0.6002\n",
      "Fold 4 Epoch 14 Validation Loss: 0.5822\n",
      "Epoch 15: Train Loss = 0.5828\n",
      "Fold 4 Epoch 15 Validation Loss: 0.5783\n",
      "Epoch 16: Train Loss = 0.5850\n",
      "Fold 4 Epoch 16 Validation Loss: 0.5807\n",
      "Epoch 17: Train Loss = 0.5818\n",
      "Fold 4 Epoch 17 Validation Loss: 0.5816\n",
      "Epoch 18: Train Loss = 0.5696\n",
      "Fold 4 Epoch 18 Validation Loss: 0.5790\n",
      "Epoch 19: Train Loss = 0.5599\n",
      "Fold 4 Epoch 19 Validation Loss: 0.5799\n",
      "Epoch 20: Train Loss = 0.5523\n",
      "Fold 4 Epoch 20 Validation Loss: 0.5780\n",
      "Epoch 21: Train Loss = 0.5535\n",
      "Fold 4 Epoch 21 Validation Loss: 0.5789\n",
      "Epoch 22: Train Loss = 0.5466\n",
      "Fold 4 Epoch 22 Validation Loss: 0.5801\n",
      "Epoch 23: Train Loss = 0.5475\n",
      "Fold 4 Epoch 23 Validation Loss: 0.5791\n",
      "Epoch 24: Train Loss = 0.5381\n",
      "Fold 4 Epoch 24 Validation Loss: 0.5811\n",
      "Epoch 25: Train Loss = 0.5331\n",
      "Fold 4 Epoch 25 Validation Loss: 0.5799\n",
      "\n",
      "--- Fold 5 ---\n",
      "Epoch 1: Train Loss = 2.9326\n",
      "Fold 5 Epoch 1 Validation Loss: 2.3970\n",
      "Epoch 2: Train Loss = 1.4149\n",
      "Fold 5 Epoch 2 Validation Loss: 0.7492\n",
      "Epoch 3: Train Loss = 0.8755\n",
      "Fold 5 Epoch 3 Validation Loss: 0.5925\n",
      "Epoch 4: Train Loss = 0.7895\n",
      "Fold 5 Epoch 4 Validation Loss: 0.6011\n",
      "Epoch 5: Train Loss = 0.7526\n",
      "Fold 5 Epoch 5 Validation Loss: 0.5838\n",
      "Epoch 6: Train Loss = 0.7119\n",
      "Fold 5 Epoch 6 Validation Loss: 0.5846\n",
      "Epoch 7: Train Loss = 0.6912\n",
      "Fold 5 Epoch 7 Validation Loss: 0.5707\n",
      "Epoch 8: Train Loss = 0.6706\n",
      "Fold 5 Epoch 8 Validation Loss: 0.5609\n",
      "Epoch 9: Train Loss = 0.6525\n",
      "Fold 5 Epoch 9 Validation Loss: 0.5629\n",
      "Epoch 10: Train Loss = 0.6442\n",
      "Fold 5 Epoch 10 Validation Loss: 0.5604\n",
      "Epoch 11: Train Loss = 0.6291\n",
      "Fold 5 Epoch 11 Validation Loss: 0.5760\n",
      "Epoch 12: Train Loss = 0.6304\n",
      "Fold 5 Epoch 12 Validation Loss: 0.5700\n",
      "Epoch 13: Train Loss = 0.6007\n",
      "Fold 5 Epoch 13 Validation Loss: 0.5556\n",
      "Epoch 14: Train Loss = 0.6027\n",
      "Fold 5 Epoch 14 Validation Loss: 0.5561\n",
      "Epoch 15: Train Loss = 0.5946\n",
      "Fold 5 Epoch 15 Validation Loss: 0.5778\n",
      "Epoch 16: Train Loss = 0.5865\n",
      "Fold 5 Epoch 16 Validation Loss: 0.5757\n",
      "Epoch 17: Train Loss = 0.5755\n",
      "Fold 5 Epoch 17 Validation Loss: 0.5619\n",
      "Epoch 18: Train Loss = 0.5658\n",
      "Fold 5 Epoch 18 Validation Loss: 0.5512\n",
      "Epoch 19: Train Loss = 0.5560\n",
      "Fold 5 Epoch 19 Validation Loss: 0.5572\n",
      "Epoch 20: Train Loss = 0.5512\n",
      "Fold 5 Epoch 20 Validation Loss: 0.5515\n",
      "Epoch 21: Train Loss = 0.5469\n",
      "Fold 5 Epoch 21 Validation Loss: 0.5594\n",
      "Epoch 22: Train Loss = 0.5407\n",
      "Fold 5 Epoch 22 Validation Loss: 0.5548\n",
      "Epoch 23: Train Loss = 0.5285\n",
      "Fold 5 Epoch 23 Validation Loss: 0.5655\n",
      "Epoch 24: Train Loss = 0.5321\n",
      "Fold 5 Epoch 24 Validation Loss: 0.5592\n",
      "Epoch 25: Train Loss = 0.5284\n",
      "Fold 5 Epoch 25 Validation Loss: 0.5542\n",
      "\n",
      "Average Validation Loss across 5 folds: 0.5620\n"
     ]
    }
   ],
   "source": [
    "dataset = SBERTEmbeddingDataset(train)\n",
    "\n",
    "_, model = cross_validate_kfold(\n",
    "    dataset=dataset,\n",
    "    model_fn=model_fn,\n",
    "    k=5,\n",
    "    num_epochs=25,\n",
    "    lr=1e-3,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d50c329",
   "metadata": {},
   "source": [
    "### Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e4c7e2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 29.18it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = sbert_model.encode(test[\"full_text\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Optional: Embeddings in die DataFrame schreiben\n",
    "test[\"embedding\"] = embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ba04b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBERTTestDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.ids = dataframe[\"text_id\"].tolist()\n",
    "        self.embeddings = dataframe[\"embedding\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedding = torch.tensor(self.embeddings[idx], dtype=torch.float)\n",
    "        return self.ids[idx], embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b36b23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SBERTTestDataset(test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cb04411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "predictions = []\n",
    "text_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ids, xb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        preds = model(xb)\n",
    "        preds = preds.clamp(0, 5)\n",
    "        preds = preds.cpu().numpy()\n",
    "        predictions.extend(preds.tolist())\n",
    "        text_ids.extend(ids)\n",
    "\n",
    "submission_df = pd.DataFrame(predictions, columns=[\n",
    "    \"cohesion\", \"syntax\", \"vocabulary\", \"phraseology\", \"grammar\", \"conventions\"\n",
    "])\n",
    "submission_df.insert(0, \"text_id\", text_ids)\n",
    "\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d659b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
